{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask_RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEwRRSfQaxCn"
      },
      "source": [
        "#Googleドライブにマウント\n",
        "ランタイムがGPUに設定されているか確認すること　\\\n",
        "パスやディレクトリなどは自分の環境にあわせて変えていく必要がある\\\n",
        "※初回は4行目をコメントアウトし、5-7行目のコメントアウトを外す\\\n",
        "　また、2回目以降は5-7行目をコメントアウトし、4行目のコメントアウトを外す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNoi5UhHYeyE",
        "outputId": "bc96415f-4e7f-40dc-c243-e8682de4a832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/My Drive/ColabData'\n",
        "%cd  /content/drive/My Drive/ColabData/Mask_RCNN\n",
        "#%cd  /content/drive/My Drive/ColabData\n",
        "#!git clone https://github.com/matterport/Mask_RCNN.git\n",
        "#cd Mask_RCNN"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/ColabData/Mask_RCNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSWK39Ofa1JK"
      },
      "source": [
        "#必要なパッケージをインストール\n",
        "最初にやってしまえば2回目以降は不要\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYWU8-rUZDuc"
      },
      "source": [
        "#!pip install -r requirements.txt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0LFoyJKZZYH"
      },
      "source": [
        "#!git clone https://github.com/waleedka/coco.git\n",
        "#%cd coco/PythonAPI/\n",
        "#!python setup.py build_ext install"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tGkUJWnZjfU"
      },
      "source": [
        "#%cd ../..\n",
        "#!python setup.py install"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg9OIRRmBoGr"
      },
      "source": [
        "#tensorflow及びkerasのバージョン指定\n",
        "tensorは1．x系でないとmaskrcnnは動かないので設定\n",
        "またkerasのバージョンも指定　\\\n",
        "※もしうまくいかない時はランタイムを再起動する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6U-_NQg5N2L",
        "outputId": "0a76c78b-11f1-4747-9ba6-f753ef0a906f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install keras==2.2.5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Requirement already satisfied: keras==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.6 (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWR39O_sa5FN"
      },
      "source": [
        "#Configクラスの作成\n",
        "エポックあたりのステップ数などは好きな値に変更していくこと"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtRSCjidZyPa"
      },
      "source": [
        "from mrcnn.config import Config\n",
        "\n",
        "\n",
        "class OneClassConfig(Config):\n",
        "\n",
        "    #: config名\n",
        "    NAME = \"leaf_dataset\"\n",
        "\n",
        "    #: バッチあたり画像数 (GPUのメモリが大きいなら増やしてもよい\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "    # クラス数　= 背景 + 検出クラス数\n",
        "    NUM_CLASSES = 1 + 1\n",
        "\n",
        "    # エポックあたりステップ数\n",
        "    STEPS_PER_EPOCH = 50\n",
        "\n",
        "    VALIDATION_STEPS = 5\n",
        "\n",
        "    # 提案領域のconfidenceが90%以下なら物体検出フェイズをスキップ\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9ShQMisa9Rt"
      },
      "source": [
        "#Datasetクラスの作成\n",
        "データセットは、Mask-RCNNフォルダの中に以下のようなフォルダを作る　\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Mask-RCNN \\\n",
        "　|- dataset \\\n",
        "　　　|- train \\\n",
        "　　　|　　|- image \\\n",
        "　　　|　　|　|- 1.jpg\\\n",
        "　　　|　　|　|- 2.jpg\\\n",
        "　　　|　　|　L ... \\\n",
        "　　　|　　L mask \\\n",
        "　　　|　　　 |- 1.jpg \\\n",
        "　　　|　　　 |- 2.jpg \\\n",
        "　　　|　　　 L ... \\\n",
        "　　　L valid \\\n",
        "　　　　　 |- image \\\n",
        "　　　　　 |　|- 1.jpg\\\n",
        "　　　　　 |　|- 2.jpg\\\n",
        "　　　　　 |　L ... \\\n",
        "　　　　　 L mask \\\n",
        "　　　　　　  |- 1.jpg\\\n",
        "　　　　　　  |- 2.jpg\\\n",
        "　　　　　　  L ... 　　\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "注意事項\n",
        "\n",
        "1.   imageフォルダとmaskフォルダ内の画像の名前は一致するようにすること\n",
        "2.   jpg画像を利用すること(ほかの形式には対応していない)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDUmug6DZ5Te",
        "outputId": "a6b87025-cf88-41b5-ef66-66e4b82ae323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pathlib\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from mrcnn import utils\n",
        "from mrcnn.model import log\n",
        "import copy\n",
        "\n",
        "\n",
        "class OneClassDataset(utils.Dataset):\n",
        "\n",
        "    def load_dataset(self, dataset_dir):\n",
        "        \"\"\" データセットを登録\n",
        "        \"\"\"\n",
        "        #: データセット名、クラスID、クラス名\n",
        "        self.add_class('leaf_dataset', 1, 'leaf')\n",
        "        \n",
        "        #images = glob.glob(\"/content/drive/My Drive/ColabData/Mask_RCNN/dataset/train/image/*.jpg\")\n",
        "        #if dataset_dir == '/content/drive/My Drive/ColabData/Mask_RCNN/dataset/train':\n",
        "        #  for i in range(1,4):\n",
        "        #    images = glob.glob(os.path.join(dataset_dir, \"image\",str(i)+\".jpg\"))\n",
        "        #print(dataset_dir)\n",
        "        images = glob.glob(os.path.join(dataset_dir, \"image\",\"*.jpg\"))\n",
        "        print(images)\n",
        "        #masks = glob.glob(\"/content/drive/My Drive/ColabData/Mask_RCNN/dataset/train/mask/*.jpg\")\n",
        "        masks = glob.glob(os.path.join(dataset_dir, \"mask\",\"*.jpg\"))\n",
        "        print(masks)\n",
        "\n",
        "        for image_path, mask_path in zip(images, masks):\n",
        "            image_path = pathlib.Path(image_path)\n",
        "            mask_path = pathlib.Path(mask_path)\n",
        "            #print(mask_path)\n",
        "            assert image_path.name == mask_path.name, 'データセット名不一致'\n",
        "\n",
        "            image = Image.open(image_path)\n",
        "            height = image.size[0]\n",
        "            width = image.size[1]\n",
        "\n",
        "            mask = Image.open(mask_path)\n",
        "            assert image.size == mask.size, \"サイズ不一致\"\n",
        "\n",
        "            self.add_image(\n",
        "                'leaf_dataset',\n",
        "                path=image_path,\n",
        "                image_id=image_path.stem,\n",
        "                mask_path=mask_path,\n",
        "                width=width, height=height)\n",
        "\n",
        "\n",
        "    def blob_detection(self, mask_path):\n",
        "        mask = cv2.imread(mask_path, 0)\n",
        "        #: 念のためもう一度二値化\n",
        "        _, mask = cv2.threshold(mask, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        label = cv2.connectedComponentsWithStats(mask)\n",
        "        data = copy.deepcopy(label[1])\n",
        "\n",
        "        labels = []\n",
        "        for label in np.unique(data):\n",
        "            #: ラベル0は背景\n",
        "            if label == 0:\n",
        "                continue\n",
        "            else:\n",
        "                labels.append(label)\n",
        "\n",
        "        mask = np.zeros((mask.shape)+(len(labels),), dtype=np.uint8)\n",
        "\n",
        "        for n, label in enumerate(labels):\n",
        "            mask[:, :, n] = np.uint8(data == label)\n",
        "\n",
        "        cls_idxs = np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "\n",
        "        return mask, cls_idxs\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"マスクデータとクラスidを生成する\n",
        "        \"\"\"\n",
        "        image_info = self.image_info[image_id]\n",
        "        if image_info[\"source\"] != 'leaf_dataset':\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "\n",
        "        mask_path = image_info['mask_path']\n",
        "        mask, cls_idxs = self.blob_detection(str(mask_path))\n",
        "\n",
        "        return mask, cls_idxs\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == 'leaf_dataset':\n",
        "            return info\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFNimYdNbAdK"
      },
      "source": [
        "#学習の実行\n",
        "データセットへのパスはそれぞれ自分に合わせて設定すること"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ya4TLu2aQ3i"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import utils\n",
        "\n",
        "\n",
        "TRAIN_DATASET = os.path.join(\"/content/drive/My Drive/ColabData/Mask_RCNN/dataset/train\")\n",
        "#TRAIN_DATASET = os.path.join('dataset', 'train')\n",
        "dataset_train = OneClassDataset()\n",
        "dataset_train.load_dataset(TRAIN_DATASET)\n",
        "dataset_train.prepare()\n",
        "\n",
        "VALID_DATASET = os.path.join(\"/content/drive/My Drive/ColabData/Mask_RCNN/dataset/valid\")\n",
        "#VALID_DATASET = os.path.join('datset', 'valid')\n",
        "dataset_val = OneClassDataset()\n",
        "dataset_val.load_dataset(VALID_DATASET)\n",
        "dataset_val.prepare()\n",
        "\n",
        "config = OneClassConfig()\n",
        "#config.display()\n",
        "\n",
        "model = modellib.MaskRCNN(mode=\"training\", model_dir=\"logs/model\",\n",
        "                          config=config)\n",
        "\n",
        "COCO_MODEL_PATH = 'mask_rcnn_coco.h5'\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                    exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
        "                            \"mrcnn_bbox\", \"mrcnn_mask\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4Ext-RJR87C"
      },
      "source": [
        "#: ネットワークのhead部分のみの訓練\n",
        "model.train(dataset_train, dataset_val,\n",
        "            learning_rate=0.001,\n",
        "            epochs=30,\n",
        "            layers='heads')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnmyA3-s4Xap"
      },
      "source": [
        "#validデータで推論を行い結果を表示(保存)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U0D09fF4FRW"
      },
      "source": [
        "class InferenceConfig(OneClassConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    DETECTION_MIN_CONFIDENCE = 0.5"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTnmfX0E4L34"
      },
      "source": [
        "    import random\n",
        "    import skimage.io\n",
        "    from mrcnn.visualize import display_images\n",
        "    from mrcnn import visualize\n",
        "    from mrcnn.model import log\n",
        "    from PIL import Image\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    VALID_DATASET = os.path.join('dataset', 'valid')\n",
        "    dataset_val = OneClassDataset()\n",
        "    dataset_val.load_dataset(VALID_DATASET)\n",
        "    dataset_val.prepare()\n",
        "\n",
        "    config = InferenceConfig()\n",
        "    MODEL_DIR = os.path.join(\"logs\", \"model\")\n",
        "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
        "                              config=config)\n",
        "    \n",
        "    weights_path = model.find_last()\n",
        "    print(\"Loading weights \", weights_path)\n",
        "    model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "    \n",
        "    #id = random.choice(dataset_val.image_ids)　#ランダムな1枚の画像を処理するとき\n",
        "    for image_id in dataset_val.image_ids:\n",
        "      image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset_val, config, image_id)\n",
        "      info = dataset_val.image_info[image_id]\n",
        "    \n",
        "      results = model.detect([image], verbose=1)\n",
        "      #ax = get_ax(1)\n",
        "      r = results[0]\n",
        "\n",
        "      \"\"\"\n",
        "      # 結果を表示する場合はこちらを使う\n",
        "      visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'],\n",
        "                                                 dataset_val.class_names, r['scores'], show_bbox=True, show_mask=True,\n",
        "                                                 title=\"Predictions\")\n",
        "      \"\"\"\n",
        "      \"\"\"  \n",
        "      #結果を保存する場合はこちらを使う\n",
        "      N = r['rois'].shape[0]\n",
        "      result_image = image\n",
        "      colors = visualize.random_colors(N)\n",
        "      for i in range(N):\n",
        "        #Color\n",
        "        color = colors[i]\n",
        "        rgb = (round(color[0] * 255), round(color[1] * 255), round(color[2] * 255))\n",
        "        \n",
        "        #Rect\n",
        "        result_image = visualize.draw_box(result_image, r['rois'][i], rgb)\n",
        "        \n",
        "        #Label & Score\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        text = dataset_val.class_names[r['class_ids'][i]] + ':' + str(r['scores'][i])\n",
        "        result_image = cv2.putText(result_image, text,\n",
        "            (r['rois'][i][1],r['rois'][i][0]), font, 0.8, rgb, 2, cv2.LINE_AA)\n",
        "        #print(class_names[r['class_ids'][i]])\n",
        "        \n",
        "        #Mask\n",
        "        mask = r['masks'][:, :, i]\n",
        "        result_image = visualize.apply_mask(result_image, mask, color)\n",
        "\n",
        "        result_image = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)\n",
        "        #result_image.save(\"/content/drive/My Drive/ColabData/Mask_RCNN/dataset/result/\" + str(image_id) + \".jpg\")\n",
        "        #skimage.io.imshow(result_image)\n",
        "        #plt.show()                                        \n",
        "        cv2.imwrite(\"/content/drive/My Drive/ColabData/Mask_RCNN/dataset/result/\" + str(image_id) + \".jpg\",result_image)\n",
        "      \"\"\"\n",
        "      \"\"\"\n",
        "      r['rois']には矩形の座標\n",
        "      r['masks']にはrois内でmaskをかける座標\n",
        "      r['class_ids']には検知した物体の名前\n",
        "      r['scores']には物体の検知精度 \n",
        "      \"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}